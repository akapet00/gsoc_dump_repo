{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/brian-team/brian2modelfitting/issues/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from brian2 import *\n",
    "import sbi.utils\n",
    "import sbi.analysis\n",
    "import sbi.inference\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultclock.dt = 0.1 * ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(params, I=1*nA, t_on=50*ms, t_total=350*ms):\n",
    "    \"\"\"\n",
    "    Simulates the HH-model with Brian2 for parameter sets in params and the\n",
    "    given input current (injection of I between t_on and t_total-t_on).\n",
    "    Returns a dictionary {'t': time steps, 'v': voltage,\n",
    "                          'I_inj': current, 'spike_count': spike count}.\n",
    "    \"\"\"\n",
    "    assert t_total > 2*t_on\n",
    "    t_off = t_total - t_on\n",
    "    \n",
    "    params = np.atleast_2d(params)\n",
    "    # fixed parameters\n",
    "    gleak = 10*nS\n",
    "    Eleak = -70*mV\n",
    "    VT = -60.0*mV\n",
    "    C = 200*pF\n",
    "    ENa = 53*mV\n",
    "    EK = -107*mV\n",
    "\n",
    "    # The conductance-based model\n",
    "    eqs = '''\n",
    "         dVm/dt = -(gNa*m**3*h*(Vm - ENa) + gK*n**4*(Vm - EK) + gleak*(Vm - Eleak) - I_inj) / C : volt\n",
    "         I_inj = int(t >= t_on and t < t_off)*I : amp (shared)\n",
    "         dm/dt = alpham*(1-m) - betam*m : 1\n",
    "         dn/dt = alphan*(1-n) - betan*n : 1\n",
    "         dh/dt = alphah*(1-h) - betah*h : 1\n",
    "         alpham = (-0.32/mV) * (Vm - VT - 13.*mV) / (exp((-(Vm - VT - 13.*mV))/(4.*mV)) - 1)/ms : Hz\n",
    "         betam = (0.28/mV) * (Vm - VT - 40.*mV) / (exp((Vm - VT - 40.*mV)/(5.*mV)) - 1)/ms : Hz\n",
    "         alphah = 0.128 * exp(-(Vm - VT - 17.*mV) / (18.*mV))/ms : Hz\n",
    "         betah = 4/(1 + exp((-(Vm - VT - 40.*mV)) / (5.*mV)))/ms : Hz\n",
    "         alphan = (-0.032/mV) * (Vm - VT - 15.*mV) / (exp((-(Vm - VT - 15.*mV)) / (5.*mV)) - 1)/ms : Hz\n",
    "         betan = 0.5*exp(-(Vm - VT - 10.*mV) / (40.*mV))/ms : Hz\n",
    "         # The parameters to fit\n",
    "         gNa : siemens (constant)\n",
    "         gK : siemens (constant)\n",
    "         '''\n",
    "    neurons = NeuronGroup(params.shape[0], eqs, threshold='m>0.5', refractory='m>0.5',\n",
    "                          method='exponential_euler', name='neurons')\n",
    "    Vm_mon = StateMonitor(neurons, 'Vm', record=True, name='Vm_mon')\n",
    "    spike_mon = SpikeMonitor(neurons, record=False, name='spike_mon')  #record=False â†’ do not record times\n",
    "    neurons.gNa_ = params[:, 0]*uS\n",
    "    neurons.gK = params[:, 1]*uS\n",
    "\n",
    "    neurons.Vm = 'Eleak'\n",
    "    neurons.m = '1/(1 + betam/alpham)'         # Would be the solution when dm/dt = 0\n",
    "    neurons.h = '1/(1 + betah/alphah)'         # Would be the solution when dh/dt = 0\n",
    "    neurons.n = '1/(1 + betan/alphan)'         # Would be the solution when dn/dt = 0\n",
    "\n",
    "    run(t_total)\n",
    "    # For convenient plotting, reconstruct the current\n",
    "    I_inj = ((Vm_mon.t >= t_on) & (Vm_mon.t < t_off))*I\n",
    "    return dict(v=Vm_mon.Vm,\n",
    "                t=Vm_mon.t,\n",
    "                I_inj=I_inj,\n",
    "                spike_count=spike_mon.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper(params):\n",
    "    obs = simulate(params)\n",
    "    Vm = obs['v'] / mV\n",
    "    return Vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_min = [.5, 1e-4]\n",
    "prior_max = [80., 15.]\n",
    "prior = sbi.utils.torchutils.BoxUniform(low=torch.as_tensor(prior_min),\n",
    "                                        high=torch.as_tensor(prior_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = prior.sample((10000, ))\n",
    "x = torch.tensor(simulation_wrapper(theta), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SinLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        linear = torch.matmul(x, self.w0) + self.b0\n",
    "        periodic = torch.sin(torch.matmul(x, self.w) + self.b)\n",
    "        return torch.cat([linear, periodic], axis=1)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            f'in_features={self.in_features}, '\n",
    "            f'out_features={self.out_features}')\n",
    "    \n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Time2Vec, self).__init__()\n",
    "        self.p1 = SinLayer(in_features, hidden_features)\n",
    "        self.p2 = SinLayer(hidden_features, hidden_features)\n",
    "        self.l = nn.Linear(hidden_features, embeddings_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.p1(x)\n",
    "        x = self.p2(x)\n",
    "        x = self.l(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "in_features = x.shape[1]\n",
    "hidden_features = 100\n",
    "embeddings_size = 10\n",
    "embedding_net = Time2Vec()\n",
    "print(embedding_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_esimator = sbi.utils.posterior_nn(model='maf', embedding_net=embedding_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = sbi.inference.SNPE(prior, density_estimator=density_esimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = inference.append_simulations(theta, x).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = inference.build_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = np.array([[32., 1.]])\n",
    "x_o = torch.tensor(simulation_wrapper(true_params), dtype=torch.float32)\n",
    "\n",
    "samples = posterior.sample((10000,), x=x_o, show_progress_bars=False)\n",
    "labels_params = [r'$\\overline{g}_{Na}$', r'$\\overline{g}_{K}$']\n",
    "sbi.analysis.pairplot(samples,\n",
    "                      figsize=(6, 6),\n",
    "                      points=true_params,\n",
    "                      labels=labels_params,\n",
    "                      points_offdiag={'markersize': 6},\n",
    "                      points_colors=['r'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
